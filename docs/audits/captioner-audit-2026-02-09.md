# Captioner Module Audit — 2026-02-09

**Reviewer**: captioner-review
**Scope**: `src/captioner.py`, `tests/test_captioner.py`, integration in `video_processor.py`, `main.py`, `config.yaml`, `models.py`
**Spec**: `tasks/auto-captions-plan.md`

---

## Spec Compliance Summary

The implementation deviates from the spec in several ways. Some simplifications are reasonable; others represent missing features or spec requirements that were dropped without documentation.

| Spec Requirement | Implementation | Status |
|---|---|---|
| Separate `src/transcriber.py` + `src/caption_generator.py` | Merged into single `src/captioner.py` | Simplified (OK) |
| Model named `TranscriptWord` | Named `CaptionWord` | Renamed (OK) |
| `utterances=True` in Deepgram options | `utterances=False` | Changed |
| Max 3 words per chunk | Max 4 words per chunk | Changed |
| Break on punctuation (`.!?`) and comma | Not implemented | **MISSING** |
| Break on gap > 0.3s | Break on gap > 0.7s | Relaxed |
| Text upper-cased for Shorts style | Not implemented | **MISSING** |
| `silence_offset` parameter on `generate_captions()` | Not implemented — silence handled in `crop_to_vertical` | Moved (but see CAP-H1) |
| `detect_leading_silence` made public | Still private `_detect_leading_silence` | Not done |
| Per-streamer `captions: bool` field on `StreamerConfig` | Not implemented | **MISSING** |
| `captions_enabled: bool` on `PipelineConfig` | Read from `raw_config["captions"]["enabled"]` instead | Different location |
| `.ass` and `.wav` in `clean_stale_tmp` suffixes | Not added | **MISSING** |
| Feature branch `feature/auto-captions` | Work appears on `master` | Deviated |
| Soft warning if `captions_enabled` but no `DEEPGRAM_API_KEY` | Not implemented in `run_pipeline` | **MISSING** |
| `deepgram-sdk>=3.0.0` in `requirements.txt` | Need to verify | See CAP-M5 |

---

## Findings

### CAP-C1 — Critical — Effort S
**Location**: `src/captioner.py:37-38`
**Issue**: Entire audio file is read into memory (`buffer_data = f.read()`). For a 60-second clip at 16kHz mono 16-bit WAV, this is ~1.9MB — fine. But there is no file size guard. If `extract_audio` produces a corrupt or unexpectedly large file (e.g., ffmpeg bug writing a multi-GB file), this will OOM the process. In CI with limited memory, this is a real risk.
**Fix**: Add a file size check before reading. Cap at e.g. 50MB: `if os.path.getsize(audio_path) > 50_000_000: log.warning(...); return None`. Alternatively, use Deepgram's streaming/file URL API to avoid loading into memory.

### CAP-C2 — High — Effort S
**Location**: `src/video_processor.py:396-406`
**Issue**: The `subtitles=` ffmpeg filter is used for ASS files. While `subtitles=` does support ASS files when ffmpeg is compiled with libass (standard), the `ass=` filter is the more correct and explicit choice for pre-generated ASS files. The `subtitles=` filter attempts to read embedded subtitles from a *video* file (it probes the input), which adds unnecessary overhead and may behave differently than expected with a standalone ASS file. Additionally, `subtitles=` may not correctly apply all ASS style overrides in some edge cases. The `ass=` filter directly renders ASS without the video-probing overhead.
**Fix**: Replace `subtitles='{escaped}'` with `ass='{escaped}'` in both the composite and simple filter paths at lines 402 and 406.

### CAP-H1 — High — Effort M
**Location**: `src/captioner.py:49-52`, `src/video_processor.py:222-224`
**Issue**: The spec calls for `silence_offset` to be subtracted from caption timestamps so captions sync with the trimmed video. Currently, `crop_to_vertical` trims leading silence via `-ss` at line 222, but the ASS file generated by `captioner.py` uses the original untrimmed timestamps. This means captions will be out of sync by `silence_offset` seconds — potentially up to 5 seconds of desync.
**Fix**: Either (a) pass `silence_offset` from `crop_to_vertical` back to the captioner to adjust timestamps, or (b) generate captions AFTER silence detection and subtract the offset in `_group_words`/`generate_ass_subtitles`. The spec anticipated this with the `silence_offset` parameter on `generate_captions()`.

### CAP-H2 — High — Effort S
**Location**: `src/captioner.py:31`
**Issue**: `from deepgram import DeepgramClient, FileSource, PrerecordedOptions` is imported inside the function body on every call to `transcribe_clip`. While this avoids import errors when `deepgram-sdk` isn't installed, it also means:
1. Every transcription call pays the import overhead
2. `FileSource` is imported but only used as a type annotation hint in `payload: FileSource = ...` — this is a runtime type hint that adds no value since Python doesn't enforce it
3. If the import fails (SDK not installed), the error message is the generic exception handler's "Deepgram transcription failed" which doesn't tell the user to install the SDK
**Fix**: Move the import to the top of the file with a try/except that sets a flag (`_DEEPGRAM_AVAILABLE = False`). Check the flag early in `transcribe_clip` and log a clear message: "deepgram-sdk not installed — pip install deepgram-sdk".

### CAP-H3 — High — Effort S
**Location**: `src/captioner.py:49`
**Issue**: `client.listen.rest.v("1").transcribe_file(payload, options)` — no timeout parameter. The Deepgram SDK supports a `timeout` option. If Deepgram's API is slow or unresponsive, this call will hang indefinitely, blocking the entire pipeline.
**Fix**: Add a timeout to the Deepgram call. The SDK's `transcribe_file` supports `options` with a `timeout` field, or wrap with a socket/signal timeout. A 30-second timeout is reasonable for clips under 60 seconds.

### CAP-H4 — High — Effort S
**Location**: `src/captioner.py:50-52`
**Issue**: No bounds checking on the Deepgram response structure. The chain `response.results.channels[0].alternatives[0].words` assumes: (a) `results` exists, (b) `channels` is non-empty, (c) `alternatives` is non-empty, (d) `words` exists. If Deepgram returns an unexpected response (empty transcript, API error wrapped in a response, model change), this will throw an `IndexError` or `AttributeError` caught by the generic except — but the error message won't indicate which part of the response was missing.
**Fix**: Add explicit checks: `if not response.results or not response.results.channels: return None`. This gives better debugging information and handles edge cases more gracefully.

### CAP-H5 — High — Effort S
**Location**: `src/captioner.py:158`, `src/video_processor.py:402`
**Issue**: ASS dialogue text is not escaped. ASS format has special characters that must be escaped: `\n` (newline), `\N` (forced newline), `{` and `}` (override tags). If Twitch streamer speech contains literal curly braces or backslash-N sequences, the ASS renderer will interpret them as formatting commands, potentially breaking rendering.
**Fix**: Escape special characters in caption text: replace `\` with `\\`, `{` with `\{`, `}` with `\}` before writing dialogue lines.

### CAP-M1 — Medium — Effort S
**Location**: `src/captioner.py:90-120`
**Issue**: The spec calls for 1-3 words per chunk; the implementation uses max 4. The spec also requires breaking on sentence punctuation (`.!?`) and commas, which is not implemented. The gap threshold is 0.7s vs the spec's 0.3s. These differences affect caption readability — shorter chunks with punctuation breaks produce more natural-feeling captions for Shorts.
**Fix**: Align with spec: max 3 words, add punctuation break logic, reduce gap threshold to 0.3s. Or document the intentional deviation and rationale.

### CAP-M2 — Medium — Effort S
**Location**: `src/captioner.py:123-168`
**Issue**: The spec requires text to be upper-cased ("Text upper-cased for Shorts style"). This is not implemented. Upper-case captions are a standard Shorts/TikTok style choice for readability.
**Fix**: Add `.upper()` to the text join: `text = " ".join(w.word for w in group).upper()`.

### CAP-M3 — Medium — Effort S
**Location**: `src/models.py:38-46`
**Issue**: The spec calls for `captions: bool | None = None` on `StreamerConfig` to enable per-streamer caption control. This is not implemented. Currently captions are only configurable globally, meaning you can't enable captions for one streamer while disabling for another.
**Fix**: Add `captions: bool | None = None` field to `StreamerConfig`. In `_process_streamer`, resolve as `streamer.captions if streamer.captions is not None else captions_enabled`.

### CAP-M4 — Medium — Effort S
**Location**: `main.py:113`
**Issue**: The spec calls for `.ass` and `.wav` to be added to `clean_stale_tmp` suffixes. Current suffixes are `(".mp4", ".mp4.tmp", ".part", ".ytdl")`. Stale `.ass` and `.wav` files from failed caption runs will accumulate in `tmp_dir` and never be cleaned up.
**Fix**: Add `".ass"` and `".wav"` to the `suffixes` tuple on line 113.

### CAP-M5 — Medium — RESOLVED
**Location**: `requirements.txt:7`
**Issue**: The spec requires `deepgram-sdk>=3.0.0` in `requirements.txt`. Verified: it IS present at line 7. However, the lazy import pattern in `captioner.py` is inconsistent with having it as a hard dependency — if it's in `requirements.txt`, it should be imported at the top level. If it's meant to be optional, it shouldn't be in the main `requirements.txt`.
**Fix**: Either move import to top-level (since SDK is a hard dep), or move to `requirements-captions.txt` and keep the lazy import.

### CAP-M6 — Medium — Effort S
**Location**: `src/captioner.py:147`
**Issue**: The ASS style uses `Bold=-1` (line 147: `-1,0,0,0`). In ASS, Bold=-1 means "use OS default" which is often regular weight, not bold. The spec calls for "Arial Bold 72pt". To get actual bold text, use `Bold=1` or specify "Arial Bold" as the font name.
**Fix**: Change `-1,0,0,0` to `1,0,0,0` for the Bold field, or use `Fontname=Arial Bold`.

### CAP-M7 — Medium — Effort S
**Location**: `src/captioner.py:148`
**Issue**: The ASS style has `Alignment=2` (bottom-center) and `MarginV=120`. The spec calls for `MarginV=400` to position text in the "lower-middle" of the 1080x1920 frame. With `MarginV=120` on a 1920px tall frame, captions will appear very close to the bottom edge, potentially overlapping with YouTube's UI elements (like/share/subscribe buttons on Shorts).
**Fix**: Change `MarginV` from 120 to 400 (or similar) to position captions in the lower-middle area, safely above YouTube's Shorts UI overlay.

### CAP-M8 — Medium — Effort S
**Location**: `src/captioner.py:148`
**Issue**: The ASS style specifies `Outline=3` but the spec calls for `4px` outline. The outline size affects caption readability against varying backgrounds. 3px may be too thin for some gameplay content.
**Fix**: Change `Outline` from 3 to 4 to match spec.

### CAP-L1 — Low — Effort S
**Location**: `src/captioner.py:163`
**Issue**: The ASS file is opened with `encoding="utf-8"` (correct) but there's no BOM. Some older ASS renderers on Windows may not handle UTF-8 without BOM correctly. However, ffmpeg's libass handles UTF-8 fine without BOM, so this is a minor compatibility concern.
**Fix**: No action needed for the ffmpeg pipeline, but worth noting for potential future use with other renderers.

### CAP-L2 — Low — Effort S
**Location**: `tests/test_captioner.py:33-34`
**Issue**: The test for centiseconds rounding accepts two possible values: `"0:00:02.00"` or `"0:00:01.99"`. This is because `_format_ass_time(1.999)` has a rounding edge case: `seconds % 1 = 0.999`, `round(0.999 * 100) = 100`, clamped to 99, so `s=1, cs=99` giving `0:00:01.99`. But `seconds % 60 = 1` (int truncation of 1.999), so the actual behavior is deterministic — the test should assert the specific correct value `"0:00:01.99"` rather than accepting both.
**Fix**: Change the assertion to `assert result == "0:00:01.99"` since that's the deterministic output.

### CAP-L3 — Low — Effort S
**Location**: `tests/test_captioner.py:146-159`
**Issue**: `test_missing_api_key_returns_none` uses `patch.dict("os.environ", env, clear=True)` which clears ALL environment variables. This could interfere with other tests if running in parallel, and may cause unexpected behavior if any imported module caches env vars at import time. Additionally, using `clear=True` is unnecessarily aggressive — just ensuring `DEEPGRAM_API_KEY` is absent is sufficient.
**Fix**: Simplify to `with patch.dict("os.environ", {}, clear=False): del os.environ["DEEPGRAM_API_KEY"]` or just mock `os.environ.get` for the specific key.

### CAP-L4 — Low — Effort S
**Location**: `src/captioner.py:19-20`
**Issue**: `clip_id` is derived from the video filename via `os.path.splitext(os.path.basename(video_path))[0]`. If the video filename contains characters that are invalid in filenames on Windows (e.g., `:`), the `os.path.join` for `audio_path` will fail silently or produce unexpected paths. The Twitch clip IDs used in this project appear safe, but this is fragile.
**Fix**: Sanitize `clip_id` before using in path construction, or at minimum document the assumption that clip IDs are filename-safe.

---

## Test Coverage Analysis

### Covered paths:
- `_format_ass_time`: zero, seconds, minutes, hours, negative clamping, rounding edge case
- `_group_words`: empty, single word, max-4 split, gap break, duration break, no-break
- `generate_ass_subtitles`: valid output, timing format, multiple groups, resolution
- `transcribe_clip`: missing API key, audio extraction failure
- `generate_captions`: transcription failure, success, ASS generation failure

### NOT covered (gaps):
1. **`transcribe_clip` with Deepgram SDK mocked** — no test exercises the actual Deepgram response parsing path (lines 30-68). The happy path of transcribe_clip is never tested with a mocked Deepgram SDK response.
2. **`transcribe_clip` with empty Deepgram response** — the `if not words:` branch (line 63) is never tested.
3. **`_remove_file`** — never directly tested (only exercised indirectly via error paths).
4. **`generate_ass_subtitles` with empty words** — `_group_words([])` returns `[]`, so the ASS file will have headers but no Dialogue lines. This path isn't tested.
5. **Windows path handling** — no tests exercise Windows-style paths with backslashes through `_escape_subtitle_path` or subtitle burn-in.
6. **Unicode/special character handling** — no tests verify that words containing ASS special characters (`{}`, `\n`, `\N`) are handled correctly.
7. **Large transcript** — no test verifies behavior with hundreds of words (memory, performance).
8. **Concurrent tmp file access** — no test for race conditions on shared `tmp_dir`.

---

## Summary

| Severity | Count | Finding IDs |
|----------|-------|-------------|
| Critical | 1 | CAP-C1 |
| High | 6 | CAP-C2, CAP-H1, CAP-H2, CAP-H3, CAP-H4, CAP-H5 |
| Medium | 8 | CAP-M1, CAP-M2, CAP-M3, CAP-M4, CAP-M5, CAP-M6, CAP-M7, CAP-M8 |
| Low | 4 | CAP-L1, CAP-L2, CAP-L3, CAP-L4 |
| **Total** | **19** | |

### Top Priority Items:
1. **CAP-H1** (High): Caption timestamps not adjusted for silence trimming — up to 5s desync
2. **CAP-C1** (Critical): No file size guard on audio buffer read
3. **CAP-C2** (High): `subtitles=` filter should be `ass=` filter for ASS files
4. **CAP-H3** (High): No timeout on Deepgram API call
5. **CAP-H5** (High): ASS special characters not escaped in dialogue text
